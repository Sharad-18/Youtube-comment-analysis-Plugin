{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcprzLu2_OP2",
        "outputId": "24f77f16-c502-4e61-fcdf-e786ccdfb594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.17.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==2.17.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.17.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (16.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.35)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.0)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.0->mlflow)\n",
            "  Downloading databricks_sdk-0.35.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.20.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.37b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.17.0-py3-none-any.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.17.0-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.35.0-py3-none-any.whl (568 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m568.4/568.4 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed Mako-1.3.6 alembic-1.13.3 databricks-sdk-0.35.0 docker-7.1.0 graphene-3.4 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.17.0 mlflow-skinny-2.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "token=userdata.get('DAGSHUB_PAT')"
      ],
      "metadata": {
        "id": "01njWzXt_UAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import mlflow\n",
        "\n",
        "\n",
        "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = token\n",
        "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = token\n",
        "\n",
        "dagshub_url = \"https://dagshub.com\"\n",
        "repo_owner = \"Sharad-18\"\n",
        "repo_name = \"Mini-Mlops-Project\"\n",
        "\n",
        "# Set up MLflow tracking URI\n",
        "mlflow.set_tracking_uri(\"https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hkTKE25O_ckM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 2 - BoW vs TfIdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15J2EJir_gge",
        "outputId": "ae1c93d0-d62c-41f8-d855-9451fb28b319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/22 06:51:30 INFO mlflow.tracking.fluent: Experiment with name 'Exp 2 - BoW vs TfIdf' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='mlflow-artifacts:/1238d60516be48af84e858d4665a560e', creation_time=1729579890384, experiment_id='2', last_update_time=1729579890384, lifecycle_stage='active', name='Exp 2 - BoW vs TfIdf', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
        "import mlflow.sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "AE2jtNzS_qw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/reddit_preprocessing (1).csv')\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42Nz7GojF0YT",
        "outputId": "aef5d172-7377-405e-baa1-53328245f03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36793, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna(subset=['clean_comment'])"
      ],
      "metadata": {
        "id": "ew8n7G-MMS7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BJ5vob4MjD3",
        "outputId": "48a1ee2d-8c92-4968-8466-8a0f2cd5425b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36662, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "def run_experiment(vectorizer_type,ngram_range,vectorizer_max_feayures,vectorizer_name):\n",
        "  if vectorizer_type==\"Bow\":\n",
        "    vectorizer=CountVectorizer(max_features=vectorizer_max_feayures,ngram_range=ngram_range)\n",
        "  else:\n",
        "    vectorizer=TfidfVectorizer(ngram_range=ngram_range,max_features=vectorizer_max_feayures)\n",
        "  X_train,X_test,y_train,y_test=train_test_split(df['clean_comment'],df['category'],test_size=0.2,random_state=42,stratify=df['category'])\n",
        "  X_train=vectorizer.fit_transform(X_train)\n",
        "  X_test=vectorizer.transform(X_test)\n",
        "\n",
        "  with mlflow.start_run() as run:\n",
        "    mlflow.set_tag(\"mlflow.runName\",f\"{vectorizer_name}_{ngram_range}_RandomFOrest\")\n",
        "    mlflow.set_tag(\"experiment_type\",\"featire_engineering\")\n",
        "    mlflow.set_tag(\"model_type\",\"RandomForest\")\n",
        "\n",
        "    n_estimators=200\n",
        "    max_depth=15\n",
        "\n",
        "    mlflow.log_param(\"n_estimators\",n_estimators)\n",
        "    mlflow.log_param(\"max_depth\",max_depth)\n",
        "\n",
        "    model=RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth)\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    y_pred=model.predict(X_test)\n",
        "\n",
        "    accuracy=accuracy_score(y_test,y_pred=y_pred)\n",
        "    mlflow.log_metric(\"accuracy\",accuracy)\n",
        "\n",
        "    classification_rep=classification_report(y_test,y_pred=y_pred,output_dict=True)\n",
        "    for label,metrics in classification_rep.items():\n",
        "      if isinstance(metrics,dict):\n",
        "        for metric,value in metrics.items():\n",
        "          mlflow.log_metric(f\"{label}_{metric}\",value)\n",
        "    conf_metrix=confusion_matrix(y_test,y_pred)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(conf_metrix,annot=True,fmt=\"d\",cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(f\"Confusion Matrix: {vectorizer_name}, {ngram_range}\")\n",
        "    plt.savefig(\"confusion_matrix.png\")\n",
        "    mlflow.log_artifact(\"confusion_matrix.png\")\n",
        "    plt.close()\n",
        "    mlflow.sklearn.log_model(model,f\"random_forest_model_{vectorizer_name}_{ngram_range}\")\n",
        "ngram_ranges=[(1,1),(1,2),(1,3)]\n",
        "max_features=5000\n",
        "for ngram_range in ngram_ranges:\n",
        "  run_experiment(\"Bow\",ngram_range,max_features,\"BoW\")\n",
        "  run_experiment(\"TfIdf\",ngram_range,max_features,\"TfIdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcviR3IJGf6X",
        "outputId": "147295c6-f129-450b-a607-00749d656679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/22 07:49:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 07:49:58 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run BoW_(1, 1)_RandomFOrest at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/94b6812f05e94a2b8d9913c7c1bba4a9.\n",
            "2024/10/22 07:49:58 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 07:50:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 07:50:18 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TfIdf_(1, 1)_RandomFOrest at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/724eecf8aabe43f193e3282feceeaf96.\n",
            "2024/10/22 07:50:18 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 07:50:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 07:50:39 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run BoW_(1, 2)_RandomFOrest at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/d4980b54b40c4816b888a342f14c6ea5.\n",
            "2024/10/22 07:50:39 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 07:50:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 07:51:01 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TfIdf_(1, 2)_RandomFOrest at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/86010128269b45ed878c9d2be11c4b50.\n",
            "2024/10/22 07:51:01 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 07:51:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 07:51:25 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run BoW_(1, 3)_RandomFOrest at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/88f0e69f844244e9a5bb802c422c97e7.\n",
            "2024/10/22 07:51:25 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 07:51:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 07:51:54 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TfIdf_(1, 3)_RandomFOrest at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/2588bbce7f544e05b65d0b3bfbd56786.\n",
            "2024/10/22 07:51:54 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/reddit_preprocessing (1).csv')\n",
        "df.shape\n",
        "df=df.dropna(subset=['clean_comment'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roE9j_KwLI0g",
        "outputId": "7836aeb2-b8dc-4246-e445-20185e055cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36793, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna(subset=['clean_comment'])"
      ],
      "metadata": {
        "id": "k64MqbcaQB7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Function to run the experiment\n",
        "def run_experiment_tfidf_max_features(max_features):\n",
        "    ngram_range = (1, 3)  # Trigram setting\n",
        "\n",
        "    # Step 2: Vectorization using TF-IDF with varying max_features\n",
        "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train)\n",
        "    X_test = vectorizer.transform(X_test)\n",
        "\n",
        "    # Step 4: Define and train a Random Forest model\n",
        "    with mlflow.start_run() as run:\n",
        "        # Set tags for the experiment and run\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"TFIDF_Trigrams_max_features_{max_features}\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
        "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "        # Add a description\n",
        "        mlflow.set_tag(\"description\", f\"RandomForest with TF-IDF Trigrams, max_features={max_features}\")\n",
        "\n",
        "        # Log vectorizer parameters\n",
        "        mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
        "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
        "        mlflow.log_param(\"vectorizer_max_features\", max_features)\n",
        "\n",
        "        # Log Random Forest parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Step 5: Make predictions and log metrics\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(f\"Confusion Matrix: TF-IDF Trigrams, max_features={max_features}\")\n",
        "        plt.savefig(\"confusion_matrix.png\")\n",
        "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"random_forest_model_tfidf_trigrams_{max_features}\")\n",
        "\n",
        "# Step 6: Test various max_features values\n",
        "max_features_values = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
        "\n",
        "for max_features in max_features_values:\n",
        "    run_experiment_tfidf_max_features(max_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCbFoVUZPIi6",
        "outputId": "7c2513df-03b8-4af6-8306-bb1d7c921305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/22 08:03:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:03:42 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TFIDF_Trigrams_max_features_1000 at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/dadeb6f92aea4a54841dd690a3b07c62.\n",
            "2024/10/22 08:03:42 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 08:04:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:04:19 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TFIDF_Trigrams_max_features_2000 at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/00a74e3094ed4f68a8264d59e0d53349.\n",
            "2024/10/22 08:04:19 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 08:04:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:04:49 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TFIDF_Trigrams_max_features_3000 at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/006126e09892430b9f7a6e5afe6ed61d.\n",
            "2024/10/22 08:04:49 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 08:05:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:05:18 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TFIDF_Trigrams_max_features_4000 at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/2a9be94ea66a4d1ca80d086eee4bee48.\n",
            "2024/10/22 08:05:18 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 08:05:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:05:46 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TFIDF_Trigrams_max_features_5000 at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/9a0f36fbec3f474da18f775d02bce284.\n",
            "2024/10/22 08:05:46 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 08:06:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:06:15 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TFIDF_Trigrams_max_features_6000 at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/a64aa64d40b5470c9b2899bf3b76e123.\n",
            "2024/10/22 08:06:15 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 08:06:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:06:42 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TFIDF_Trigrams_max_features_7000 at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/33d9aadf819d486fb36d183f94ccc0a1.\n",
            "2024/10/22 08:06:42 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 08:07:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:07:10 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TFIDF_Trigrams_max_features_8000 at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/ea28d88837984f9a92d17d80b9ed5106.\n",
            "2024/10/22 08:07:10 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 08:07:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:07:38 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TFIDF_Trigrams_max_features_9000 at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/f4dac84ab8f34e16bd871dd94ab6d713.\n",
            "2024/10/22 08:07:38 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n",
            "2024/10/22 08:08:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:08:06 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run TFIDF_Trigrams_max_features_10000 at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2/runs/5ed73541e60b4d49bec67cb1619512d5.\n",
            "2024/10/22 08:08:06 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/reddit_preprocessing (1).csv')\n",
        "df.shape\n",
        "df=df.dropna(subset=['clean_comment'])"
      ],
      "metadata": {
        "id": "XoS_IIvxQExk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 4 - Handling Imbalanced Data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwvrhWyUXM7C",
        "outputId": "545e47b3-167a-4b98-8f90-20090820505a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /Sharad-18/Youtube-comment-analysis-Plugin.mlflow/api/2.0/mlflow/experiments/get-by-name?experiment_name=Exp+4+-+Handling+Imbalanced+Data\n",
            "2024/10/22 08:34:23 INFO mlflow.tracking.fluent: Experiment with name 'Exp 4 - Handling Imbalanced Data' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='mlflow-artifacts:/eb17a0cc395a4800a41ee125a39c49d2', creation_time=1729586063668, experiment_id='3', last_update_time=1729586063668, lifecycle_stage='active', name='Exp 4 - Handling Imbalanced Data', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "08_kHpkeXf9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Function to run the experiment\n",
        "def run_imbalanced_experiment(imbalance_method):\n",
        "    ngram_range = (1, 3)  # Trigram setting\n",
        "    max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
        "\n",
        "    # Step 4: Train-test split before vectorization and resampling\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "    # Step 2: Vectorization using TF-IDF, fit on training data only\n",
        "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
        "    X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
        "\n",
        "    # Step 3: Handle class imbalance based on the selected method (only applied to the training set)\n",
        "    if imbalance_method == 'class_weights':\n",
        "        # Use class_weight in Random Forest\n",
        "        class_weight = 'balanced'\n",
        "    else:\n",
        "        class_weight = None  # Do not apply class_weight if using resampling\n",
        "\n",
        "        # Resampling Techniques (only apply to the training set)\n",
        "        if imbalance_method == 'oversampling':\n",
        "            smote = SMOTE(random_state=42)\n",
        "            X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
        "        elif imbalance_method == 'adasyn':\n",
        "            adasyn = ADASYN(random_state=42)\n",
        "            X_train_vec, y_train = adasyn.fit_resample(X_train_vec, y_train)\n",
        "        elif imbalance_method == 'undersampling':\n",
        "            rus = RandomUnderSampler(random_state=42)\n",
        "            X_train_vec, y_train = rus.fit_resample(X_train_vec, y_train)\n",
        "        elif imbalance_method == 'smote_enn':\n",
        "            smote_enn = SMOTEENN(random_state=42)\n",
        "            X_train_vec, y_train = smote_enn.fit_resample(X_train_vec, y_train)\n",
        "\n",
        "    # Step 5: Define and train a Random Forest model\n",
        "    with mlflow.start_run() as run:\n",
        "        # Set tags for the experiment and run\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"Imbalance_{imbalance_method}_RandomForest_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"imbalance_handling\")\n",
        "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "        # Add a description\n",
        "        mlflow.set_tag(\"description\", f\"RandomForest with TF-IDF Trigrams, imbalance handling method={imbalance_method}\")\n",
        "\n",
        "        # Log vectorizer parameters\n",
        "        mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
        "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
        "        mlflow.log_param(\"vectorizer_max_features\", max_features)\n",
        "\n",
        "        # Log Random Forest parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "        mlflow.log_param(\"imbalance_method\", imbalance_method)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42, class_weight=class_weight)\n",
        "        model.fit(X_train_vec, y_train)\n",
        "\n",
        "        # Step 6: Make predictions and log metrics\n",
        "        y_pred = model.predict(X_test_vec)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(f\"Confusion Matrix: TF-IDF Trigrams, Imbalance={imbalance_method}\")\n",
        "        confusion_matrix_filename = f\"confusion_matrix_{imbalance_method}.png\"\n",
        "        plt.savefig(confusion_matrix_filename)\n",
        "        mlflow.log_artifact(confusion_matrix_filename)\n",
        "        plt.close()\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"random_forest_model_tfidf_trigrams_imbalance_{imbalance_method}\")\n",
        "\n",
        "# Step 7: Run experiments for different imbalance methods\n",
        "imbalance_methods = ['class_weights', 'oversampling', 'adasyn', 'undersampling', 'smote_enn']\n",
        "\n",
        "for method in imbalance_methods:\n",
        "    run_imbalanced_experiment(method)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e10m0URjXHAD",
        "outputId": "2c0d7ce8-eb09-45da-9721-bd6f93082a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/22 08:36:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:36:12 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run Imbalance_class_weights_RandomForest_TFIDF_Trigrams at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/3/runs/914a951350ef4849891d5210fd716b6d.\n",
            "2024/10/22 08:36:12 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/3.\n",
            "2024/10/22 08:36:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:36:44 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run Imbalance_oversampling_RandomForest_TFIDF_Trigrams at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/3/runs/a29ff5250b2b4f89a09c944fa538b7df.\n",
            "2024/10/22 08:36:44 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/3.\n",
            "2024/10/22 08:37:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:37:33 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run Imbalance_adasyn_RandomForest_TFIDF_Trigrams at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/3/runs/e02f33316fde4e29a4205d394d8fdb51.\n",
            "2024/10/22 08:37:33 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/3.\n",
            "2024/10/22 08:37:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:38:02 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run Imbalance_undersampling_RandomForest_TFIDF_Trigrams at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/3/runs/060da336cd1449d2af95c74229d19132.\n",
            "2024/10/22 08:38:02 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/3.\n",
            "2024/10/22 08:39:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/22 08:39:22 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run Imbalance_smote_enn_RandomForest_TFIDF_Trigrams at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/3/runs/b52c299fa8ae4f5b8b435948f7928074.\n",
            "2024/10/22 08:39:22 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: https://dagshub.com/Sharad-18/Youtube-comment-analysis-Plugin.mlflow/#/experiments/3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GNzXC_hCXO6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}